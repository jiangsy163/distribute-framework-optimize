#配置文件优化

##01. hdfs-site.xml

01. 128MB的块性能高于64MB、256MB和384MB；

		<property>
			<name>dfs.block.size</name>
			<value>134217728</value>
		</property>


02. NameNode与DataNode通信线程数，增大至40；

		<property>
			<name>dfs.namenode.handler.count</name>
			<value>40</value>
		</property>


03. 数据节点打开文件上限属性；

		<property>
			<name>dfs.datanode.max.xcievers</name>
			<value>65536</value>
		</property>


04. start-balancer.sh宽带默认 1048576（1MB/s）,增大到20MB/s；

		<property>
			<name>dfs.balance.bandwidthPerSec</name>
			<value>20485760</value>
		</property>



05. 配置默认HDFS文件副本数目，默认是3；

		<property>
			<name>dfs.replication</name>
			<value>3</value>
		</property>

#02. core-site.xml

00. 设置HDFS文件读写以及中间结果缓冲区大小，默认4KB，增加至128KB；128*1024=13172

		<property>
			<name>io.file.buffer.size</name>
			<value>131072</value>
		</property>


00. reduce阶段合并map输出的内存限制，设置200MB，根据自身硬件设备进行测试；

		<property>
			<name>fs.inmemory.size.mb</name>
			<value>200</value>
		</property>

#03. mapred-site.xml






#Hadoop参数调优原则：
1. 增大作业的并行程度，比如增大Map的任务数
2. 保证任务执行时有足够的资源
3. 满足前两者，尽可能为shuffle阶段提供资源

上述原则同样适用于Spark。
